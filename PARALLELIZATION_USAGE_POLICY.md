# Parallel AI Coding - ä¸¦åˆ—åŒ–åˆ©ç”¨æ–¹é‡ (Parallelization Usage Policy)

**Version**: 1.0.0
**Last Updated**: 2025-10-24
**Status**: âœ… Production Ready
**Target**: ã™ã¹ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆäººé–“ãƒ»AIï¼‰

---

## ğŸ¯ Executive Summary

ã“ã®æ–‡æ›¸ã¯ã€ä¸¦åˆ—AIã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã®**é©åˆ‡ãªä½¿ç”¨æ–¹é‡**ã‚’å®šç¾©ã—ã¾ã™ã€‚

**åŸºæœ¬åŸå‰‡**:
1. âœ… **è‡ªç™ºçš„ã‚¿ã‚¹ã‚¯åˆ†æ** - ã™ã¹ã¦ã®çŠ¶æ³ã§ã‚¿ã‚¹ã‚¯åˆ†å‰²å¯èƒ½æ€§ã‚’è‡ªå‹•è©•ä¾¡
2. âœ… **å®‰å…¨å„ªå…ˆ** - ç«¶åˆãƒªã‚¹ã‚¯ãŒã‚ã‚‹å ´åˆã¯é©åˆ‡ãªç®¡ç†æ‰‹æ³•ã‚’é©ç”¨
3. âœ… **åŠ¹ç‡æœ€é©åŒ–** - Workeré–“ã®å‡¦ç†æ™‚é–“ã‚’å¯èƒ½ãªé™ã‚Šå‡ç­‰åŒ–
4. âš ï¸ **æ…é‡ãªåˆ¤æ–­** - å±é™ºãªåˆ†å‰²ã‚„ä¸å¿…è¦ãªåˆ†å‰²ã¯å›é¿

---

## ğŸ“‹ Table of Contents

1. [åŸºæœ¬æ–¹é‡](#åŸºæœ¬æ–¹é‡)
2. [ã‚¿ã‚¹ã‚¯åˆ†å‰²åˆ¤æ–­åŸºæº–](#ã‚¿ã‚¹ã‚¯åˆ†å‰²åˆ¤æ–­åŸºæº–)
3. [ä¸¦åˆ—åŒ–æ±ºå®šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ](#ä¸¦åˆ—åŒ–æ±ºå®šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ )
4. [Workerå‰²ã‚Šå½“ã¦æˆ¦ç•¥](#workerå‰²ã‚Šå½“ã¦æˆ¦ç•¥)
5. [å®‰å…¨æ€§ç®¡ç†](#å®‰å…¨æ€§ç®¡ç†)
6. [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–](#ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–)
7. [ç¦æ­¢äº‹é …](#ç¦æ­¢äº‹é …)
8. [ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹](#ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹)

---

## ğŸ”° åŸºæœ¬æ–¹é‡

### åŸå‰‡1: è‡ªç™ºçš„ã‚¿ã‚¹ã‚¯åˆ†æ (Proactive Task Analysis)

**ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã€è‡ªå‹•çš„ã«ä¸¦åˆ—åŒ–å¯èƒ½æ€§ã‚’è©•ä¾¡ã™ã‚‹**

```python
# æ“¬ä¼¼ã‚³ãƒ¼ãƒ‰
def analyze_task(task: Task) -> ParallelizationDecision:
    """
    ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ã‚’è‡ªå‹•åˆ†æ

    Returns:
        ParallelizationDecision: ä¸¦åˆ—åŒ–åˆ¤æ–­çµæœ
    """
    # Step 1: ã‚¿ã‚¹ã‚¯è¤‡é›‘åº¦åˆ†æ
    complexity = assess_complexity(task)

    # Step 2: ä¾å­˜é–¢ä¿‚åˆ†æ
    dependencies = analyze_dependencies(task)

    # Step 3: ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆãƒªã‚¹ã‚¯è©•ä¾¡
    conflict_risk = assess_conflict_risk(task)

    # Step 4: ä¸¦åˆ—åŒ–ä¾¡å€¤åˆ¤å®š
    parallelization_value = calculate_value(
        complexity, dependencies, conflict_risk
    )

    # Step 5: æ±ºå®š
    if parallelization_value > THRESHOLD:
        return ParallelizationDecision.PARALLEL
    else:
        return ParallelizationDecision.SEQUENTIAL
```

### åŸå‰‡2: å®‰å…¨å„ªå…ˆ (Safety First)

**ç«¶åˆãƒªã‚¹ã‚¯ãŒã‚ã‚‹å ´åˆã¯é©åˆ‡ãªç®¡ç†æ‰‹æ³•ã‚’è‡ªå‹•é©ç”¨**

```
ç«¶åˆãƒªã‚¹ã‚¯è©•ä¾¡ â†’ ç®¡ç†æ‰‹æ³•é¸æŠ:

ğŸŸ¢ LOW RISK (0-20%)
   â†’ Subprocess ãƒ¢ãƒ¼ãƒ‰ (æœ€é€Ÿ)
   â†’ Gitç®¡ç†ä¸è¦

ğŸŸ¡ MEDIUM RISK (20-50%)
   â†’ Git Worktree ãƒ¢ãƒ¼ãƒ‰ (ãƒ•ã‚¡ã‚¤ãƒ«åˆ†é›¢)
   â†’ è‡ªå‹•ãƒãƒ¼ã‚¸æˆ¦ç•¥

ğŸ”´ HIGH RISK (50-80%)
   â†’ Git Worktree + æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼
   â†’ Sequential fallback option

ğŸ”´ CRITICAL RISK (80-100%)
   â†’ Sequentialå®Ÿè¡Œã®ã¿
   â†’ ä¸¦åˆ—åŒ–ä¸­æ­¢
```

### åŸå‰‡3: åŠ¹ç‡æœ€é©åŒ– (Efficiency Optimization)

**Workeré–“ã®å‡¦ç†æ™‚é–“ã‚’å¯èƒ½ãªé™ã‚Šå‡ç­‰åŒ–**

```python
# ã‚¿ã‚¹ã‚¯å‰²ã‚Šå½“ã¦æœ€é©åŒ–
def optimize_task_allocation(tasks: List[Task]) -> List[WorkerAssignment]:
    """
    å‡¦ç†æ™‚é–“ã‚’å‡ç­‰åŒ–ã™ã‚‹ã‚ˆã†ã«ã‚¿ã‚¹ã‚¯ã‚’å‰²ã‚Šå½“ã¦

    ç›®æ¨™: å…¨Workerã®å®Œäº†æ™‚é–“å·® < 20%
    """
    # Step 1: å„ã‚¿ã‚¹ã‚¯ã®æ¨å®šæ™‚é–“è¨ˆç®—
    estimated_times = [estimate_duration(t) for t in tasks]

    # Step 2: Bin Packing Problem ã¨ã—ã¦è§£ã
    # (Longest Processing Time First ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ )
    assignments = lpt_algorithm(tasks, estimated_times, num_workers)

    # Step 3: è² è·ãƒãƒ©ãƒ³ã‚¹æ¤œè¨¼
    max_time = max(sum(t for _, t in worker) for worker in assignments)
    min_time = min(sum(t for _, t in worker) for worker in assignments)

    assert (max_time - min_time) / max_time < 0.20, "Load imbalance > 20%"

    return assignments
```

---

## ğŸ§® ã‚¿ã‚¹ã‚¯åˆ†å‰²åˆ¤æ–­åŸºæº–

### Decision Matrix: ä¸¦åˆ—åŒ–ã™ã¹ãã‹ï¼Ÿ

| æ¡ä»¶ | ä¸¦åˆ—åŒ– | Sequential | ç†ç”± |
|------|--------|-----------|------|
| **ã‚¿ã‚¹ã‚¯æ•° = 1** | âŒ | âœ… | åˆ†å‰²ã®ä¾¡å€¤ãªã— |
| **ã‚¿ã‚¹ã‚¯æ•° = 2, ç‹¬ç«‹** | âœ… | â–³ | 2å€é€Ÿã®å¯èƒ½æ€§ |
| **ã‚¿ã‚¹ã‚¯æ•° â‰¥ 3, ç‹¬ç«‹** | âœ… | âŒ | ä¸¦åˆ—åŒ–æ¨å¥¨ |
| **å¼·ã„ä¾å­˜é–¢ä¿‚ã‚ã‚Š** | âŒ | âœ… | Sequentialå¿…é ˆ |
| **å¼±ã„ä¾å­˜é–¢ä¿‚** | âœ… | â–³ | DAGè§£æã—ã¦ä¸¦åˆ—åŒ– |
| **åŒä¸€ãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›†** | âš ï¸ | âœ… | Worktree or Sequential |
| **ç•°ãªã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª** | âœ… | âŒ | ç«¶åˆãƒªã‚¹ã‚¯ä½ |
| **æ¨å®šæ™‚é–“ < 5åˆ†** | âŒ | âœ… | Overhead > Benefit |
| **æ¨å®šæ™‚é–“ > 30åˆ†** | âœ… | âŒ | ä¸¦åˆ—åŒ–ã§å¤§å¹…çŸ­ç¸® |
| **CPUä½¿ç”¨ç‡ > 80%** | âš ï¸ | â–³ | Workeræ•°åˆ¶é™ |
| **ãƒ¡ãƒ¢ãƒªä¸è¶³ãƒªã‚¹ã‚¯** | âŒ | âœ… | ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³ |

### ã‚¿ã‚¹ã‚¯è¤‡é›‘åº¦åˆ†é¡

```python
class TaskComplexity(Enum):
    TRIVIAL = 1        # < 5åˆ†, ä¸¦åˆ—åŒ–ä¸è¦
    SIMPLE = 2         # 5-15åˆ†, ä¸¦åˆ—åŒ–æ¤œè¨
    MODERATE = 3       # 15-30åˆ†, ä¸¦åˆ—åŒ–æ¨å¥¨
    COMPLEX = 4        # 30-60åˆ†, ä¸¦åˆ—åŒ–å¼·ãæ¨å¥¨
    VERY_COMPLEX = 5   # > 60åˆ†, å¿…ãšä¸¦åˆ—åŒ–
```

**åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯**:

```python
def should_parallelize(task: Task) -> bool:
    """ä¸¦åˆ—åŒ–åˆ¤æ–­"""

    # Rule 1: è¤‡é›‘åº¦ãƒã‚§ãƒƒã‚¯
    if task.complexity <= TaskComplexity.TRIVIAL:
        return False  # å°ã•ã™ãã‚‹

    # Rule 2: ã‚µãƒ–ã‚¿ã‚¹ã‚¯æ•°ãƒã‚§ãƒƒã‚¯
    if len(task.subtasks) < 2:
        return False  # åˆ†å‰²ã§ããªã„

    # Rule 3: ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
    if has_strong_dependencies(task):
        return False  # Sequentialå¿…é ˆ

    # Rule 4: ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆãƒã‚§ãƒƒã‚¯
    conflict_risk = assess_file_conflicts(task)
    if conflict_risk > 0.8:  # 80%ä»¥ä¸Š
        return False  # å±é™ºã™ãã‚‹

    # Rule 5: ãƒªã‚½ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯
    if not has_sufficient_resources(task):
        return False  # ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³

    # Rule 6: ä¾¡å€¤è¨ˆç®—
    value = calculate_parallelization_value(task)
    return value > 0.3  # 30%ä»¥ä¸Šã®ä¾¡å€¤
```

---

## ğŸ”€ ä¸¦åˆ—åŒ–æ±ºå®šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

### Complete Decision Flow

```
ã‚¿ã‚¹ã‚¯å—ä¿¡
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 1: ã‚¿ã‚¹ã‚¯åˆ†æ      â”‚
â”‚ - è¤‡é›‘åº¦è©•ä¾¡            â”‚
â”‚ - ã‚µãƒ–ã‚¿ã‚¹ã‚¯æŠ½å‡º        â”‚
â”‚ - æ¨å®šæ™‚é–“è¨ˆç®—          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 2: ä¾å­˜é–¢ä¿‚è§£æ    â”‚
â”‚ - DAGæ§‹ç¯‰               â”‚
â”‚ - ç‹¬ç«‹ã‚¿ã‚¹ã‚¯ç¾¤ç‰¹å®š      â”‚
â”‚ - Critical Pathåˆ†æ     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 3: ç«¶åˆãƒªã‚¹ã‚¯è©•ä¾¡  â”‚
â”‚ - ãƒ•ã‚¡ã‚¤ãƒ«é‡è¤‡æ¤œå‡º      â”‚
â”‚ - Git conflictäºˆæ¸¬      â”‚
â”‚ - ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ç®—å‡º      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
     <ãƒªã‚¹ã‚¯è©•ä¾¡>
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚
  HIGH         LOW/MED
    â”‚             â”‚
    â†“             â†“
Sequential    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
å®Ÿè¡Œ          â”‚ Step 4: ä¾¡å€¤è¨ˆç®—â”‚
    â”‚         â”‚ - æ™‚é–“çŸ­ç¸®ç‡    â”‚
    â”‚         â”‚ - Overheadè€ƒæ…®  â”‚
    â”‚         â”‚ - Cost/Benefit  â”‚
    â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                  â†“
    â”‚            <ä¾¡å€¤åˆ¤å®š>
    â”‚                  â†“
    â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚                 â”‚
    â”‚      ä¾¡å€¤ä½            ä¾¡å€¤é«˜
    â”‚         â”‚                 â”‚
    â”‚         â†“                 â†“
    â”‚    Sequential      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    å®Ÿè¡Œ            â”‚ Step 5: ä¸¦åˆ—å®Ÿè¡Œâ”‚
    â”‚         â”‚          â”‚ - Workerå‰²å½“    â”‚
    â”‚         â”‚          â”‚ - è² è·åˆ†æ•£      â”‚
    â”‚         â”‚          â”‚ - ç›£è¦–é–‹å§‹      â”‚
    â”‚         â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚         â”‚                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
                å®Ÿè¡Œé–‹å§‹
```

### åˆ¤æ–­åŸºæº–ã®æ•°å¼åŒ–

#### 1. ä¸¦åˆ—åŒ–ä¾¡å€¤ã‚¹ã‚³ã‚¢ (Parallelization Value Score)

```
PVS = (Time_Saved - Overhead) Ã— Success_Rate - Risk_Cost

Where:
  Time_Saved = Sequential_Time - Parallel_Time
  Overhead = Setup_Time + Coordination_Time + Merge_Time
  Success_Rate = 1 - Conflict_Probability
  Risk_Cost = Expected_Conflict_Resolution_Time Ã— Conflict_Probability
```

**åˆ¤å®š**:
- `PVS > 0.3` â†’ ä¸¦åˆ—åŒ–å®Ÿæ–½
- `0 < PVS â‰¤ 0.3` â†’ ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¤æ–­
- `PVS â‰¤ 0` â†’ Sequentialå®Ÿè¡Œ

#### 2. æœ€é©Workeræ•°è¨ˆç®—

```
Optimal_Workers = min(
    Available_CPU_Cores - 1,
    Independent_Task_Count,
    floor(Total_Estimated_Time / Min_Task_Time),
    Max_Workers_Config
)
```

**åˆ¶ç´„**:
- CPU cores - 1 (ã‚·ã‚¹ãƒ†ãƒ äºˆç´„)
- Independent tasksæ•°ä»¥ä¸‹
- è² è·ãƒãƒ©ãƒ³ã‚¹è€ƒæ…®
- è¨­å®šä¸Šé™éµå®ˆ

#### 3. ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆãƒªã‚¹ã‚¯è©•ä¾¡

```
Conflict_Risk = Î£(File_Overlap_i Ã— Edit_Probability_i) / Total_Files

Where:
  File_Overlap_i = è¤‡æ•°WorkerãŒè§¦ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•°
  Edit_Probability_i = ãƒ•ã‚¡ã‚¤ãƒ«iãŒç·¨é›†ã•ã‚Œã‚‹ç¢ºç‡
```

**ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«**:
- `< 0.2` â†’ ğŸŸ¢ LOW
- `0.2 - 0.5` â†’ ğŸŸ¡ MEDIUM
- `0.5 - 0.8` â†’ ğŸŸ  HIGH
- `> 0.8` â†’ ğŸ”´ CRITICAL

---

## ğŸ‘· Workerå‰²ã‚Šå½“ã¦æˆ¦ç•¥

### Strategy 1: Load Balancing (è² è·åˆ†æ•£)

**ç›®æ¨™**: å…¨Workerã®å®Œäº†æ™‚é–“å·®ã‚’æœ€å°åŒ–

```python
def load_balanced_allocation(tasks: List[Task], num_workers: int) -> List[List[Task]]:
    """
    LPT (Longest Processing Time First) ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

    è¤‡é›‘åº¦: O(n log n)
    æœ€é©æ€§: 2 - 1/m è¿‘ä¼¼è§£ (m = workeræ•°)
    """
    # ã‚¿ã‚¹ã‚¯ã‚’æ¨å®šæ™‚é–“é™é †ã«ã‚½ãƒ¼ãƒˆ
    sorted_tasks = sorted(tasks, key=lambda t: t.estimated_time, reverse=True)

    # å„Workerã®ç¾åœ¨è² è·ã‚’è¿½è·¡
    worker_loads = [0.0] * num_workers
    worker_tasks = [[] for _ in range(num_workers)]

    # å„ã‚¿ã‚¹ã‚¯ã‚’æœ€ã‚‚è² è·ãŒè»½ã„Workerã«å‰²ã‚Šå½“ã¦
    for task in sorted_tasks:
        min_load_worker = min(range(num_workers), key=lambda i: worker_loads[i])
        worker_tasks[min_load_worker].append(task)
        worker_loads[min_load_worker] += task.estimated_time

    return worker_tasks
```

### Strategy 2: Module-Based Allocation (ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ¥)

**ç›®æ¨™**: ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆã‚’æœ€å°åŒ–

```python
def module_based_allocation(tasks: List[Task]) -> List[List[Task]]:
    """
    åŒã˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¿ã‚¹ã‚¯ã‚’åŒã˜Workerã«å‰²ã‚Šå½“ã¦

    åˆ©ç‚¹: ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆãƒªã‚¹ã‚¯æœ€å°åŒ–
    æ¬ ç‚¹: è² è·ä¸å‡è¡¡ã®å¯èƒ½æ€§
    """
    # ã‚¿ã‚¹ã‚¯ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    module_groups = defaultdict(list)
    for task in tasks:
        module = extract_module(task)
        module_groups[module].append(task)

    # å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—ã‚’1 Workerã«å‰²ã‚Šå½“ã¦
    allocations = []
    for module, module_tasks in module_groups.items():
        allocations.append(module_tasks)

    return allocations
```

### Strategy 3: Dependency-Aware Allocation (ä¾å­˜é–¢ä¿‚è€ƒæ…®)

**ç›®æ¨™**: ä¾å­˜é–¢ä¿‚ã‚’æº€ãŸã—ã¤ã¤ä¸¦åˆ—åº¦æœ€å¤§åŒ–

```python
def dependency_aware_allocation(tasks: List[Task]) -> List[List[Task]]:
    """
    DAG (Directed Acyclic Graph) ã«åŸºã¥ãå‰²ã‚Šå½“ã¦

    ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ : Topological Sort + Level-based Grouping
    """
    # Step 1: DAGæ§‹ç¯‰
    dag = build_dependency_graph(tasks)

    # Step 2: Topological Sort
    sorted_tasks = topological_sort(dag)

    # Step 3: ãƒ¬ãƒ™ãƒ«åˆ†ã‘ (åŒã˜ãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¹ã‚¯ã¯ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½)
    levels = []
    current_level = []
    completed = set()

    for task in sorted_tasks:
        # ä¾å­˜å…ˆãŒå…¨ã¦å®Œäº†ã—ã¦ã„ã‚Œã°current_levelã«è¿½åŠ 
        if all(dep in completed for dep in task.dependencies):
            current_level.append(task)
        else:
            # æ–°ã—ã„ãƒ¬ãƒ™ãƒ«é–‹å§‹
            if current_level:
                levels.append(current_level)
                completed.update(current_level)
            current_level = [task]

    if current_level:
        levels.append(current_level)

    return levels
```

### Strategy Selection Logic

```python
def select_allocation_strategy(
    tasks: List[Task],
    conflict_risk: float,
    dependency_complexity: float
) -> AllocationStrategy:
    """æœ€é©ãªå‰²ã‚Šå½“ã¦æˆ¦ç•¥ã‚’é¸æŠ"""

    # ä¾å­˜é–¢ä¿‚ãŒè¤‡é›‘ãªå ´åˆ
    if dependency_complexity > 0.7:
        return AllocationStrategy.DEPENDENCY_AWARE

    # ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆãƒªã‚¹ã‚¯ãŒé«˜ã„å ´åˆ
    if conflict_risk > 0.5:
        return AllocationStrategy.MODULE_BASED

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: è² è·åˆ†æ•£
    return AllocationStrategy.LOAD_BALANCED
```

---

## ğŸ›¡ï¸ å®‰å…¨æ€§ç®¡ç†

### 1. Git Conflictç®¡ç†æˆ¦ç•¥

#### Strategy A: Git Worktree (æ¨å¥¨)

**é©ç”¨æ¡ä»¶**:
- ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆãƒªã‚¹ã‚¯: MEDIUM - HIGH
- ã‚¿ã‚¹ã‚¯æ¨å®šæ™‚é–“: > 15åˆ†
- Gitç®¡ç†ã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ

**å®Ÿè£…**:
```bash
# å„Workerã«ç‹¬ç«‹ã—ãŸWorktreeã‚’ä½œæˆ
git worktree add ../workspace/worker_001 -b feature/worker-001
git worktree add ../workspace/worker_002 -b feature/worker-002
git worktree add ../workspace/worker_003 -b feature/worker-003

# Workerå®Œäº†å¾Œã«ãƒãƒ¼ã‚¸
git checkout master
git merge feature/worker-001
git merge feature/worker-002
git merge feature/worker-003
```

**åˆ©ç‚¹**:
- âœ… ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¬ãƒ™ãƒ«ã§å®Œå…¨åˆ†é›¢
- âœ… åŒæ™‚ç·¨é›†å¯èƒ½
- âœ… Gitå±¥æ­´ä¿æŒ

**æ¬ ç‚¹**:
- âš ï¸ ãƒãƒ¼ã‚¸æ™‚ã«conflictå¯èƒ½æ€§
- âš ï¸ Setup overhead (æ•°ç§’)

#### Strategy B: File Locking

**é©ç”¨æ¡ä»¶**:
- ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆãƒªã‚¹ã‚¯: LOW
- äº‹å‰ã«ãƒ•ã‚¡ã‚¤ãƒ«å‰²ã‚Šå½“ã¦æ˜ç¢º

**å®Ÿè£…**:
```yaml
# file_locks.yml
worker_001:
  - src/module_a/file1.py
  - src/module_a/file2.py

worker_002:
  - src/module_b/file1.py
  - src/module_b/file2.py

worker_003:
  - src/module_c/file1.py
```

**æ¤œè¨¼**:
```python
def validate_file_locks(workers: List[Worker]) -> bool:
    """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯"""
    all_files = []
    for worker in workers:
        all_files.extend(worker.assigned_files)

    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
    duplicates = [f for f in all_files if all_files.count(f) > 1]

    if duplicates:
        raise ConflictError(f"File lock violation: {duplicates}")

    return True
```

### 2. Rollbackæˆ¦ç•¥

#### Scenario 1: å˜ä¸€Workerå¤±æ•—

```python
def handle_worker_failure(failed_worker: Worker, all_workers: List[Worker]):
    """
    å˜ä¸€Workerå¤±æ•—æ™‚ã®å‡¦ç†

    æˆ¦ç•¥:
    1. å¤±æ•—Workerã®å¤‰æ›´ã‚’ç ´æ£„
    2. ä»–Workerã¯ç¶™ç¶š
    3. å¤±æ•—ã‚¿ã‚¹ã‚¯ã‚’å†è©¦è¡Œ or Sequentialå®Ÿè¡Œ
    """
    # Step 1: å¤±æ•—Workerã®worktreeå‰Šé™¤
    failed_worker.rollback()

    # Step 2: ä»–Workerã¯ç¶™ç¶šï¼ˆå½±éŸ¿ãªã—ï¼‰
    continue_execution(all_workers.remove(failed_worker))

    # Step 3: å¤±æ•—ã‚¿ã‚¹ã‚¯ã®å†å‡¦ç†åˆ¤æ–­
    if should_retry(failed_worker.task):
        retry(failed_worker.task, sequential=True)
    else:
        log_failure(failed_worker.task)
```

#### Scenario 2: Cascadeå¤±æ•—ï¼ˆä¾å­˜é–¢ä¿‚ï¼‰

```python
def handle_cascade_failure(
    failed_worker: Worker,
    dependent_workers: List[Worker]
):
    """
    ä¾å­˜é–¢ä¿‚ã®ã‚ã‚‹Workerç¾¤ã®å¤±æ•—å‡¦ç†

    æˆ¦ç•¥:
    1. å¤±æ•—Workerã¨ä¾å­˜Workerã‚’å…¨ã¦åœæ­¢
    2. å…¨å¤‰æ›´ã‚’ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
    3. Sequential fallback
    """
    # Step 1: ä¾å­˜Workerå…¨ã¦åœæ­¢
    for worker in dependent_workers:
        worker.stop()
        worker.rollback()

    # Step 2: Sequentialå†å®Ÿè¡Œ
    tasks = [failed_worker.task] + [w.task for w in dependent_workers]
    execute_sequential(tasks)
```

### 3. Safety Checks

#### Pre-execution Checks

```python
class SafetyValidator:
    """ä¸¦åˆ—å®Ÿè¡Œå‰ã®å®‰å…¨æ€§æ¤œè¨¼"""

    def validate_before_execution(
        self,
        tasks: List[Task],
        workers: List[Worker]
    ) -> ValidationResult:
        """å®Ÿè¡Œå‰æ¤œè¨¼"""

        checks = [
            self.check_file_conflicts(),
            self.check_resource_availability(),
            self.check_dependency_satisfaction(),
            self.check_git_status(),
            self.check_workspace_cleanliness(),
        ]

        failed_checks = [c for c in checks if not c.passed]

        if failed_checks:
            return ValidationResult(
                passed=False,
                failures=failed_checks,
                recommendation="Fix issues or use Sequential mode"
            )

        return ValidationResult(passed=True)
```

#### Runtime Monitoring

```python
class RuntimeMonitor:
    """å®Ÿè¡Œä¸­ã®ç›£è¦–"""

    def monitor_execution(self, workers: List[Worker]):
        """
        ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–

        æ¤œå‡ºé …ç›®:
        - ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆã®å…†å€™
        - ãƒªã‚½ãƒ¼ã‚¹æ¯æ¸‡
        - Workeråœæ­¢ãƒ»ã‚¨ãƒ©ãƒ¼
        - äºˆæƒ³å¤–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹
        """
        while any(w.is_running() for w in workers):
            # CPU/ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯
            if get_cpu_usage() > 95%:
                self.reduce_worker_count()

            # ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆæ¤œå‡º
            if detect_concurrent_file_access():
                self.alert_conflict_risk()

            # Workerå¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
            for worker in workers:
                if worker.is_stuck():
                    self.handle_stuck_worker(worker)

            time.sleep(1)
```

---

## âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 1. Workeræ•°ã®æœ€é©åŒ–

#### CPU-based Optimization

```python
def calculate_optimal_workers() -> int:
    """CPUãƒ™ãƒ¼ã‚¹ã®æœ€é©Workeræ•°è¨ˆç®—"""

    cpu_count = os.cpu_count()
    cpu_usage = psutil.cpu_percent(interval=1)

    # Rule 1: CPU cores - 1 (ã‚·ã‚¹ãƒ†ãƒ ç”¨ã«1 coreæ®‹ã™)
    max_workers_cpu = max(1, cpu_count - 1)

    # Rule 2: ç¾åœ¨ã®CPUä½¿ç”¨ç‡è€ƒæ…®
    if cpu_usage > 70:
        # æ—¢ã«è² è·ãŒé«˜ã„ â†’ Workeræ•°å‰Šæ¸›
        max_workers_cpu = max(1, max_workers_cpu // 2)

    return max_workers_cpu
```

#### Memory-based Optimization

```python
def calculate_memory_limit(estimated_memory_per_worker: float) -> int:
    """ãƒ¡ãƒ¢ãƒªãƒ™ãƒ¼ã‚¹ã®Workeræ•°åˆ¶é™"""

    total_memory = psutil.virtual_memory().total
    available_memory = psutil.virtual_memory().available

    # Rule: åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒªã®80%ã¾ã§ä½¿ç”¨
    usable_memory = available_memory * 0.8

    max_workers_memory = int(usable_memory / estimated_memory_per_worker)

    return max(1, max_workers_memory)
```

#### Combined Optimization

```python
def get_optimal_worker_count(
    tasks: List[Task],
    config: Config
) -> int:
    """ç·åˆçš„ãªæœ€é©Workeræ•°æ±ºå®š"""

    # å„åˆ¶ç´„ã‹ã‚‰æœ€å¤§å€¤è¨ˆç®—
    max_cpu = calculate_optimal_workers()
    max_memory = calculate_memory_limit(estimate_memory_per_task(tasks))
    max_config = config.max_workers
    max_tasks = len([t for t in tasks if not t.dependencies])

    # æœ€ã‚‚åˆ¶ç´„ãŒå³ã—ã„å€¤ã‚’æ¡ç”¨
    optimal = min(max_cpu, max_memory, max_config, max_tasks)

    # æœ€ä½1 Workerä¿è¨¼
    return max(1, optimal)
```

### 2. Timeoutæœ€é©åŒ–

```python
def calculate_optimal_timeout(task: Task) -> float:
    """ã‚¿ã‚¹ã‚¯ç‰¹æ€§ã«åŸºã¥ãTimeoutè¨ˆç®—"""

    # Base estimate
    base_timeout = task.estimated_time

    # Complexity multiplier
    complexity_multiplier = {
        TaskComplexity.TRIVIAL: 2.0,
        TaskComplexity.SIMPLE: 2.5,
        TaskComplexity.MODERATE: 3.0,
        TaskComplexity.COMPLEX: 4.0,
        TaskComplexity.VERY_COMPLEX: 5.0,
    }[task.complexity]

    # Historical performance adjustment
    historical_factor = get_historical_performance_factor(task.type)

    # Final calculation
    timeout = base_timeout * complexity_multiplier * historical_factor

    # Bounds
    min_timeout = 60  # æœ€ä½1åˆ†
    max_timeout = 3600  # æœ€å¤§1æ™‚é–“

    return max(min_timeout, min(timeout, max_timeout))
```

### 3. Overheadå‰Šæ¸›

#### Worktree Setup Optimization

```bash
# æœ€é©åŒ–å‰: å„Workerã§å€‹åˆ¥setup (é…ã„)
git worktree add ../worker_001
git worktree add ../worker_002
git worktree add ../worker_003

# æœ€é©åŒ–å¾Œ: ä¸¦åˆ—setup (é€Ÿã„)
parallel git worktree add ::: ../worker_001 ../worker_002 ../worker_003
```

#### Lazy Initialization

```python
class LazyWorker:
    """é…å»¶åˆæœŸåŒ–Worker"""

    def __init__(self, task: Task):
        self.task = task
        self._workspace = None
        self._process = None

    @property
    def workspace(self):
        """å¿…è¦ã«ãªã£ãŸã¨ãã ã‘worktreeä½œæˆ"""
        if self._workspace is None:
            self._workspace = self.create_worktree()
        return self._workspace

    def execute(self):
        """å®Ÿè¡Œé–‹å§‹æ™‚ã«åˆæœŸåŒ–"""
        # Workspaceä½œæˆã¨ãƒ—ãƒ­ã‚»ã‚¹èµ·å‹•ã‚’ä¸¦åˆ—åŒ–
        with concurrent.futures.ThreadPoolExecutor() as executor:
            workspace_future = executor.submit(self.create_worktree)
            process_future = executor.submit(self.prepare_process)

            workspace = workspace_future.result()
            process = process_future.result()

        self._workspace = workspace
        self._process = process
```

---

## ğŸš« ç¦æ­¢äº‹é …

### Absolute Prohibitions (çµ¶å¯¾ç¦æ­¢)

#### 1. å±é™ºãªãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã®ä¸¦åˆ—åŒ–

```python
# âŒ çµ¶å¯¾ã«ä¸¦åˆ—åŒ–ã—ã¦ã¯ã„ã‘ãªã„ä¾‹

# åŒä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®åŒæ™‚ç·¨é›†ï¼ˆWorktreeãªã—ï¼‰
Worker 1: Edit config.json
Worker 2: Edit config.json  # âŒ Conflictç¢ºå®Ÿ

# ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸¦åˆ—æ“ä½œ
Worker 1: Update /etc/hosts
Worker 2: Update /etc/hosts  # âŒ å±é™º

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ migration ã®ä¸¦åˆ—å®Ÿè¡Œ
Worker 1: Run migration 001
Worker 2: Run migration 002  # âŒ Data corruption risk
```

**ç†ç”±**: ãƒ‡ãƒ¼ã‚¿ç ´æã€äºˆæ¸¬ä¸å¯èƒ½ãªå‹•ä½œ

#### 2. å¼·ã„ä¾å­˜é–¢ä¿‚ã®ç„¡è¦–

```python
# âŒ é–“é•ã£ãŸä¸¦åˆ—åŒ–

# Task BãŒ Task Aã®å‡ºåŠ›ã«ä¾å­˜
Worker 1: Task A (generate data.json)
Worker 2: Task B (process data.json)  # âŒ Task Aå®Œäº†å‰ã«é–‹å§‹

# æ­£ã—ã„æ–¹æ³•
Worker 1: Task A â†’ å®Œäº†å¾…ã¡
Worker 1: Task B  # Sequentialå®Ÿè¡Œ
```

**ç†ç”±**: Task BãŒå¤±æ•—ã€æ­£ã—ã„çµæœãŒå¾—ã‚‰ã‚Œãªã„

#### 3. ãƒªã‚½ãƒ¼ã‚¹åˆ¶é™ã®ç„¡è¦–

```python
# âŒ ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ã‚’è¶…ãˆã‚‹ä¸¦åˆ—åŒ–

# CPU: 4 cores, èµ·å‹•Worker: 16
# â†’ ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ãŒåœæ­¢ã™ã‚‹å¯èƒ½æ€§

# Memory: 8GB available, Worker x 10 x 1GB/worker
# â†’ OOM Killerç™ºå‹•

# æ­£ã—ã„æ–¹æ³•
max_workers = min(cpu_count - 1, available_memory / memory_per_worker)
```

**ç†ç”±**: ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã€å…¨ã‚¿ã‚¹ã‚¯å¤±æ•—

#### 4. Gitå±¥æ­´ã®ç ´å£Š

```python
# âŒ å±é™ºãªGitæ“ä½œã®ä¸¦åˆ—å®Ÿè¡Œ

Worker 1: git rebase master
Worker 2: git push --force  # âŒ å±¥æ­´ç ´å£Š

Worker 1: git commit --amend
Worker 2: git commit --amend  # âŒ Commitç«¶åˆ
```

**ç†ç”±**: Gitå±¥æ­´ç ´æã€ãƒãƒ¼ãƒ å…¨ä½“ã«å½±éŸ¿

### Discouraged Patterns (éæ¨å¥¨)

#### 1. éåº¦ãªç´°åˆ†åŒ–

```python
# ğŸŸ¡ éæ¨å¥¨: Overhead > Benefit

# 5åˆ†ã®ã‚¿ã‚¹ã‚¯ã‚’10å€‹ã«åˆ†å‰²
for i in range(10):
    Worker(task_i)  # å„30ç§’

# Setup overhead: 5ç§’/worker x 10 = 50ç§’
# å®Ÿè¡Œæ™‚é–“: 30ç§’ï¼ˆä¸¦åˆ—ï¼‰
# Total: 80ç§’ vs Sequential: 5åˆ† (300ç§’)
# â†’ ä¸¦åˆ—åŒ–ä¾¡å€¤ã‚ã‚Šï¼ˆç´„4å€é€Ÿï¼‰

# ã—ã‹ã—ã€1åˆ†ã®ã‚¿ã‚¹ã‚¯ã‚’10å€‹ã«åˆ†å‰²ã¯ï¼Ÿ
# å®Ÿè¡Œæ™‚é–“: 6ç§’ï¼ˆä¸¦åˆ—ï¼‰
# Total: 56ç§’ vs Sequential: 60ç§’
# â†’ ä¸¦åˆ—åŒ–ä¾¡å€¤ä½ã„ï¼ˆç´„1.07å€é€Ÿã®ã¿ï¼‰
```

**ç›®å®‰**: ã‚¿ã‚¹ã‚¯1ã¤ã‚ãŸã‚Šæœ€ä½5åˆ†ä»¥ä¸Š

#### 2. ä¸å‡ç­‰ãªè² è·åˆ†æ•£

```python
# ğŸŸ¡ éæ¨å¥¨: è² è·ä¸å‡è¡¡

Worker 1: Task A (60åˆ†)
Worker 2: Task B (5åˆ†)
Worker 3: Task C (5åˆ†)

# Worker 1å®Œäº†ã¾ã§2,3ã¯å¾…æ©Ÿ â†’ åŠ¹ç‡æ‚ªã„

# æ”¹å–„ç­–
Worker 1: Task A (60åˆ†)
Worker 2: Task B (5åˆ†) â†’ Task D (25åˆ†) â†’ Task E (30åˆ†)
Worker 3: Task C (5åˆ†) â†’ Task F (55åˆ†)
```

**ç›®å®‰**: Workeré–“ã®å®Œäº†æ™‚é–“å·® < 20%

#### 3. éåº¦ãªWorkeræ•°

```python
# ğŸŸ¡ éæ¨å¥¨: Workeræ•°éå¤š

# CPU: 8 cores
# Workers: 32  # âŒ 4å€ã®oversubscription

# Context switch overheadå¢—å¤§
# å„Workerã®å®Ÿè¡Œé€Ÿåº¦ä½ä¸‹

# æ¨å¥¨
workers = cpu_count - 1  # 7 workers
```

**ç›®å®‰**: Workeræ•° â‰¤ CPU cores - 1

---

## âœ… ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. æ®µéšçš„ä¸¦åˆ—åŒ–

```python
# Phase 1: å°è¦æ¨¡ãƒ†ã‚¹ãƒˆ (1-2 workers)
result = execute_parallel(tasks, max_workers=2)
validate_results(result)

# Phase 2: ä¸­è¦æ¨¡ãƒ†ã‚¹ãƒˆ (4 workers)
result = execute_parallel(tasks, max_workers=4)
validate_results(result)

# Phase 3: Fullä¸¦åˆ—åŒ– (optimal workers)
optimal_workers = calculate_optimal_workers()
result = execute_parallel(tasks, max_workers=optimal_workers)
```

### 2. Dry-runæ¤œè¨¼

```python
def dry_run_validation(tasks: List[Task]) -> ValidationReport:
    """
    å®Ÿéš›ã«å®Ÿè¡Œã›ãšã«æ¤œè¨¼

    ãƒã‚§ãƒƒã‚¯é …ç›®:
    - ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆäºˆæ¸¬
    - ãƒªã‚½ãƒ¼ã‚¹è¦ä»¶
    - ä¾å­˜é–¢ä¿‚æº€è¶³æ€§
    - æ¨å®šå®Œäº†æ™‚é–“
    """
    report = ValidationReport()

    # é™çš„è§£æ
    report.file_conflicts = predict_file_conflicts(tasks)
    report.resource_requirements = estimate_resources(tasks)
    report.dependency_issues = validate_dependencies(tasks)
    report.estimated_time = estimate_completion_time(tasks)

    # æ¨å¥¨äº‹é …
    if report.file_conflicts > 0.5:
        report.recommendation = "Use Git Worktree mode"

    if report.resource_requirements > available_resources():
        report.recommendation = "Reduce worker count"

    return report
```

### 3. ç¶™ç¶šçš„ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

```python
class ContinuousMonitor:
    """å®Ÿè¡Œä¸­ã®ç¶™ç¶šçš„ç›£è¦–"""

    def __init__(self, workers: List[Worker]):
        self.workers = workers
        self.metrics = MetricsCollector()

    def monitor(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ"""
        while self.workers_running():
            # å„WorkerçŠ¶æ…‹
            for worker in self.workers:
                self.metrics.record({
                    'worker_id': worker.id,
                    'cpu_percent': worker.cpu_usage(),
                    'memory_mb': worker.memory_usage(),
                    'progress': worker.progress(),
                    'output_rate': worker.output_rate(),
                })

            # ã‚¢ãƒ©ãƒ¼ãƒˆåˆ¤å®š
            if self.detect_anomaly():
                self.send_alert()

            # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ›´æ–°
            self.update_dashboard()

            time.sleep(5)  # 5ç§’é–“éš”
```

### 4. Failsafeè¨­è¨ˆ

```python
class FailsafeExecutor:
    """å¤±æ•—ã«å¼·ã„å®Ÿè¡Œå™¨"""

    def execute_with_fallback(self, tasks: List[Task]) -> Result:
        """
        Fallbackæˆ¦ç•¥:
        1. ä¸¦åˆ—å®Ÿè¡Œè©¦è¡Œ
        2. å¤±æ•—æ™‚ã¯ Sequential fallback
        3. ãã‚Œã§ã‚‚å¤±æ•—ãªã‚‰äººé–“ã«ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        """
        try:
            # ä¸¦åˆ—å®Ÿè¡Œè©¦è¡Œ
            result = self.execute_parallel(tasks)

            if result.success_rate < 0.75:  # 75%æœªæº€ã®æˆåŠŸç‡
                raise ParallelExecutionError("Low success rate")

            return result

        except ParallelExecutionError as e:
            # Sequential fallback
            logger.warning(f"Parallel failed: {e}, falling back to sequential")
            return self.execute_sequential(tasks)

        except Exception as e:
            # äººé–“ã«ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            logger.error(f"All execution failed: {e}")
            return self.escalate_to_human(tasks, error=e)
```

### 5. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé§†å‹•

```python
class TaskDocumentation:
    """ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã®å®Œå…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒ–"""

    def document_execution(self, execution: Execution) -> ExecutionReport:
        """
        å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

        å«ã‚€æƒ…å ±:
        - ã‚¿ã‚¹ã‚¯åˆ†å‰²ãƒ­ã‚¸ãƒƒã‚¯
        - Workerå‰²ã‚Šå½“ã¦æˆ¦ç•¥
        - å®Ÿè¡Œæ™‚é–“è©³ç´°
        - ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³
        - ç™ºç”Ÿã—ãŸå•é¡Œã¨å¯¾å‡¦
        - å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ
        """
        return ExecutionReport(
            task_splitting=execution.splitting_logic,
            allocation_strategy=execution.allocation_strategy,
            timeline=execution.timeline,
            resources=execution.resource_usage,
            issues=execution.issues,
            lessons_learned=execution.lessons,
            success_rate=execution.success_rate,
            time_saved=execution.sequential_time - execution.parallel_time,
        )
```

---

## ğŸ“Š å®Ÿè·µä¾‹

### Example 1: Manager AIé–‹ç™º (æˆåŠŸä¾‹)

**ã‚¿ã‚¹ã‚¯**: Manager AI Week 2-3å®Ÿè£… (60æ™‚é–“)

**åˆ†æ**:
```python
# ã‚¿ã‚¹ã‚¯åˆ†å‰²
tasks = [
    Task("Claude Monitor", estimated_time=20h, module="integrations/"),
    Task("Supervisor Manager", estimated_time=20h, module="core/supervisor/"),
    Task("Dashboard & API", estimated_time=20h, module="frontend/"),
]

# ä¾å­˜é–¢ä¿‚
dependencies = {}  # å®Œå…¨ç‹¬ç«‹

# ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆãƒªã‚¹ã‚¯
conflict_risk = 0.05  # ğŸŸ¢ LOW (ç•°ãªã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª)

# ä¸¦åˆ—åŒ–ä¾¡å€¤
value = (60h - 20h) - 3h_overhead) / 60h = 0.62  # 62%ã®æ™‚é–“çŸ­ç¸®

# æ±ºå®š: ä¸¦åˆ—åŒ–æ¨å¥¨ âœ…
```

**å®Ÿè¡Œ**:
```python
workers = [
    Worker(id="001", task=tasks[0], workspace="worker_001/"),
    Worker(id="002", task=tasks[1], workspace="worker_002/"),
    Worker(id="003", task=tasks[2], workspace="worker_003/"),
]

# Git Worktree mode (å®‰å…¨æ€§å„ªå…ˆ)
for worker in workers:
    worker.create_worktree()

# ä¸¦åˆ—å®Ÿè¡Œ
results = execute_parallel(workers, max_workers=3)

# çµæœ
# å®Ÿè¡Œæ™‚é–“: 22h (overheadå«ã‚€)
# æ™‚é–“çŸ­ç¸®: 38h (63%)
# æˆåŠŸç‡: 100%
# ç«¶åˆ: 0ä»¶
```

**çµè«–**: âœ… ä¸¦åˆ—åŒ–å¤§æˆåŠŸ

### Example 2: Base Managerå®Ÿè£… (å¤±æ•—ä¾‹ã‚’å›é¿)

**ã‚¿ã‚¹ã‚¯**: BaseAIManagerå®Ÿè£… (6æ™‚é–“)

**åˆ†æ**:
```python
# ã‚¿ã‚¹ã‚¯åˆ†å‰²ï¼ˆä»®ï¼‰
tasks = [
    Task("Write base_manager.py", estimated_time=3h),
    Task("Write unit tests", estimated_time=2h),
    Task("Update documentation", estimated_time=1h),
]

# ä¾å­˜é–¢ä¿‚
dependencies = {
    tasks[1]: [tasks[0]],  # Tests depend on base_manager.py
    tasks[2]: [tasks[0]],  # Docs depend on base_manager.py
}

# ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆãƒªã‚¹ã‚¯
conflict_risk = 0.9  # ğŸ”´ CRITICAL (åŒä¸€ãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›†)

# ä¸¦åˆ—åŒ–ä¾¡å€¤
# Task 1ãŒå®Œäº†ã—ãªã„ã¨Task 2,3é–‹å§‹ä¸å¯
# å®Ÿè³ªçš„ã«Sequentialå®Ÿè¡Œã¨åŒã˜

value = 0.1  # 10%ã®æ™‚é–“çŸ­ç¸®ï¼ˆoverheadè€ƒæ…®ã™ã‚‹ã¨ãƒã‚¤ãƒŠã‚¹ï¼‰

# æ±ºå®š: ä¸¦åˆ—åŒ–ã—ãªã„ âŒ
```

**å®Ÿè¡Œ**:
```python
# Sequentialå®Ÿè¡Œ
execute_sequential([tasks[0], tasks[1], tasks[2]])

# çµæœ
# å®Ÿè¡Œæ™‚é–“: 6h
# æ™‚é–“çŸ­ç¸®: 0h (ä¸¦åˆ—åŒ–ãªã—)
# ç«¶åˆ: 0ä»¶ (Sequentialå®Ÿè¡Œ)
# å“è³ª: é«˜ (é›†ä¸­ã—ã¦å®Ÿè£…)
```

**çµè«–**: âœ… Sequentialå®Ÿè¡ŒãŒæ­£ã—ã„é¸æŠ

### Example 3: Frontend Componenté–‹ç™º (ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰)

**ã‚¿ã‚¹ã‚¯**: 5ã¤ã®Reactã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆä½œæˆ (å„2æ™‚é–“)

**åˆ†æ**:
```python
tasks = [
    Task("ComponentA", 2h, file="ComponentA.tsx"),
    Task("ComponentB", 2h, file="ComponentB.tsx"),
    Task("ComponentC", 2h, file="ComponentC.tsx"),
    Task("ComponentD", 2h, file="ComponentD.tsx"),
    Task("ComponentE", 2h, file="ComponentE.tsx"),
]

# ä¾å­˜é–¢ä¿‚: ComponentAãŒåŸºåº•ã‚¯ãƒ©ã‚¹ã€ä»–ã¯ç‹¬ç«‹
dependencies = {
    tasks[1]: [tasks[0]],
    tasks[2]: [tasks[0]],
    tasks[3]: [tasks[0]],
    tasks[4]: [tasks[0]],
}

# ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆãƒªã‚¹ã‚¯
conflict_risk = 0.1  # ğŸŸ¢ LOW (ç•°ãªã‚‹ãƒ•ã‚¡ã‚¤ãƒ«)

# ä¸¦åˆ—åŒ–ä¾¡å€¤ï¼ˆPhase 1 sequential, Phase 2 parallelï¼‰
value = 0.5  # 50%ã®æ™‚é–“çŸ­ç¸®
```

**å®Ÿè¡Œ**:
```python
# Phase 1: ComponentAï¼ˆåŸºåº•ã‚¯ãƒ©ã‚¹ï¼‰ã‚’å…ˆã«å®Ÿè£…
execute_sequential([tasks[0]])  # 2h

# Phase 2: ä»–4ã¤ã‚’ä¸¦åˆ—å®Ÿè£…
execute_parallel(tasks[1:5], max_workers=4)  # 2h

# Total: 4h vs Sequential: 10h
# æ™‚é–“çŸ­ç¸®: 6h (60%)
```

**çµè«–**: âœ… ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè¡ŒãŒæœ€é©

---

## ğŸ“ å­¦ç¿’ã¨æ”¹å–„

### Continuous Learning

```python
class ParallelizationLearner:
    """ä¸¦åˆ—åŒ–ã®å­¦ç¿’ãƒ»æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.history = []
        self.model = None

    def record_execution(self, execution: Execution):
        """å®Ÿè¡Œçµæœã‚’è¨˜éŒ²"""
        self.history.append({
            'task_characteristics': execution.task_characteristics,
            'parallelization_decision': execution.decision,
            'actual_time': execution.actual_time,
            'estimated_time': execution.estimated_time,
            'success_rate': execution.success_rate,
            'conflicts': execution.conflicts,
        })

    def learn(self):
        """å±¥æ­´ã‹ã‚‰å­¦ç¿’"""
        # æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§æœ€é©åŒ–
        features = extract_features(self.history)
        self.model = train_model(features)

    def predict_optimal_strategy(self, new_task: Task) -> Strategy:
        """æ–°ã‚¿ã‚¹ã‚¯ã®æœ€é©æˆ¦ç•¥äºˆæ¸¬"""
        features = extract_features([new_task])
        return self.model.predict(features)
```

### Feedback Loop

```
å®Ÿè¡Œ â†’ çµæœè¨˜éŒ² â†’ åˆ†æ â†’ å­¦ç¿’ â†’ æ”¹å–„ â†’ æ¬¡å›å®Ÿè¡Œ
  â†‘                                         â†“
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š å‚è€ƒè³‡æ–™

### é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

1. [HYBRID_ENGINE_GUIDE.md](docs/HYBRID_ENGINE_GUIDE.md) - Safety architecture
2. [user_guide.md](docs/user_guide.md) - Complete usage guide
3. [PARALLEL_EXECUTION_IMPLEMENTATION.md](docs/PARALLEL_EXECUTION_IMPLEMENTATION.md)
4. [PARALLEL_DEVELOPMENT_FEASIBILITY_ANALYSIS.md](PARALLEL_DEVELOPMENT_FEASIBILITY_ANALYSIS.md)

### ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å‚è€ƒæ–‡çŒ®

- **Load Balancing**: Graham's List Scheduling (LPT algorithm)
- **Dependency Analysis**: Topological Sort (Kahn's algorithm)
- **Bin Packing**: First Fit Decreasing (FFD)
- **Graph Theory**: Critical Path Method (CPM)

---

## ğŸ“ Appendix: Quick Reference

### Decision Checklist

```
â–¡ ã‚¿ã‚¹ã‚¯æ•° â‰¥ 2 ?
â–¡ ç‹¬ç«‹ã‚¿ã‚¹ã‚¯ or å¼±ã„ä¾å­˜é–¢ä¿‚?
â–¡ ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆãƒªã‚¹ã‚¯ < 50% ?
â–¡ æ¨å®šæ™‚é–“ > 15åˆ† ?
â–¡ ãƒªã‚½ãƒ¼ã‚¹ååˆ†?
â–¡ ä¸¦åˆ—åŒ–ä¾¡å€¤ > 30% ?

âœ… å…¨ã¦YES â†’ ä¸¦åˆ—åŒ–å®Ÿæ–½
âš ï¸ ä¸€éƒ¨NO â†’ æ…é‡ã«åˆ¤æ–­
âŒ å¤šãNO â†’ Sequentialå®Ÿè¡Œ
```

### Command Examples

```bash
# Dry-run (æ¤œè¨¼ã®ã¿)
python orchestrator.py --dry-run --tasks task1,task2,task3

# ä¸¦åˆ—å®Ÿè¡Œ (auto worker count)
python orchestrator.py --parallel --tasks task1,task2,task3

# Workeræ•°æŒ‡å®š
python orchestrator.py --parallel --workers 4 --tasks task1,task2,task3

# Git Worktree mode
python orchestrator.py --parallel --mode worktree --tasks task1,task2,task3

# ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°æœ‰åŠ¹
python orchestrator.py --parallel --monitor --tasks task1,task2,task3
```

---

**Document Version**: 1.0.0
**Last Updated**: 2025-10-24
**Authors**: Claude (Sonnet 4.5) + User Collaboration
**Status**: âœ… Production Ready

**License**: MIT
**Feedback**: ã“ã®ãƒãƒªã‚·ãƒ¼ã¯ç¶™ç¶šçš„ã«æ”¹å–„ã•ã‚Œã¾ã™ã€‚ææ¡ˆã‚„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ãŠå¾…ã¡ã—ã¦ã„ã¾ã™ã€‚
